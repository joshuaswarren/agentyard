#!/usr/bin/env bash
#
# agentsmd  –  manage AGENTS.md files with migration-style best practices
#
# Usage:  agentsmd [options]
#
# The script:
#   • Creates symlinks for CLAUDE.md and GEMINI.md pointing to AGENTS.md
#   • Generates or updates AGENTS.md files with versioned best practices
#   • Uses Claude Code to analyze repositories for project-specific content
#   • Tracks applied migrations in .agentyard-version.yml
#   • Caches analysis results for performance
#
# Dependencies: claude (Claude Code CLI), git, yq (YAML processor)
#
set -euo pipefail

prog=$(basename "$0")

# Configuration
# Determine if we're in development (agentyard repo) or production
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Configure multi-tier repository paths
declare -a AGENTSMD_REPOS=()
declare -a TIER_NAMES=()

# Always check public repo first
if [[ -d "${SCRIPT_DIR}/../agentsmd" ]]; then
  # Development mode - use local agentsmd directory
  AGENTSMD_REPOS+=("${SCRIPT_DIR}/../agentsmd")
  TIER_NAMES+=("public")
else
  # Production mode - use ~/agentyard/agentsmd
  if [[ -d "${HOME}/agentyard/agentsmd" ]]; then
    AGENTSMD_REPOS+=("${HOME}/agentyard/agentsmd")
    TIER_NAMES+=("public")
  fi
fi

# Check for team repo
if [[ -d "${HOME}/agentyard-team/agentsmd" ]]; then
  AGENTSMD_REPOS+=("${HOME}/agentyard-team/agentsmd")
  TIER_NAMES+=("team")
fi

# Check for private repo
if [[ -d "${HOME}/agentyard-private/agentsmd" ]]; then
  AGENTSMD_REPOS+=("${HOME}/agentyard-private/agentsmd")
  TIER_NAMES+=("private")
fi

# Primary directories still come from public repo for backward compatibility
AGENTSMD_ROOT="${AGENTSMD_REPOS[0]:-${HOME}/agentyard/agentsmd}"
BEST_PRACTICES_DIR="${AGENTSMD_ROOT}/best-practices"
CACHE_DIR="${AGENTSMD_ROOT}/cache"
TEMPLATES_DIR="${AGENTSMD_ROOT}/templates"
LIB_DIR="${AGENTSMD_ROOT}/lib"
RULES_DIR="${AGENTSMD_ROOT}/rules"

# Default options
PROJECT_DIR="."
CHECK_ONLY=false
VERBOSE=false
NO_CACHE=false
LIST_MIGRATIONS=false
LIST_RULES=false
CLAUDE_MODEL="sonnet"
TIMEOUT=600
MAX_RETRIES=2
SHOW_PROMPTS=false
COMMAND=""
DRY_RUN=false
OPENAI_MODEL="o3"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

usage() {
  cat <<EOF
Usage: $prog [command] [options]

Manage AGENTS.md files with migration-style best practices

Commands:
  dedupe                  Remove duplicate text using OpenAI
  
  If no command is specified, runs the default migration behavior.

Options:
  -h, --help              Show this help message
  -c, --check-only        Preview what would be done without making changes
  -v, --verbose           Show detailed progress
  -n, --no-cache          Force fresh Claude analysis
  -p, --project <path>    Target specific directory (default: current)
  -l, --list-migrations   Show all available migrations
  --list-rules            Show all available rules
  -m, --model <model>     Claude model to use (default: sonnet)
  -t, --timeout <secs>    Timeout per Claude call (default: 600)
  -r, --max-retries <n>   Max retry attempts (default: 2)
  -s, --show-prompts      Show prompts being sent to Claude
  --dry-run               Preview changes without applying them

Dedupe Options:
  --openai-model <model> OpenAI model to use (default: o3)

Examples:
  $prog                    # Basic usage in current directory
  $prog --check-only       # Preview changes
  $prog --project ~/work/myapp --verbose
  $prog --list-migrations
  $prog dedupe            # Remove duplicates from AGENTS.md
  $prog dedupe --dry-run  # Preview duplicate removal

EOF
}

# ---- Parse command line arguments --------------------------------------------
# Check for command first
if [[ $# -gt 0 ]] && [[ "$1" != "-"* ]]; then
  COMMAND="$1"
  shift
fi

while [[ $# -gt 0 ]]; do
  case $1 in
    -h|--help)
      usage
      exit 0
      ;;
    -c|--check-only)
      CHECK_ONLY=true
      shift
      ;;
    -v|--verbose)
      VERBOSE=true
      shift
      ;;
    -n|--no-cache)
      NO_CACHE=true
      shift
      ;;
    -p|--project)
      PROJECT_DIR="$2"
      shift 2
      ;;
    -l|--list-migrations)
      LIST_MIGRATIONS=true
      shift
      ;;
    --list-rules)
      LIST_RULES=true
      shift
      ;;
    -m|--model)
      CLAUDE_MODEL="$2"
      shift 2
      ;;
    -t|--timeout)
      TIMEOUT="$2"
      shift 2
      ;;
    -r|--max-retries)
      MAX_RETRIES="$2"
      shift 2
      ;;
    -s|--show-prompts)
      SHOW_PROMPTS=true
      shift
      ;;
    --dry-run)
      DRY_RUN=true
      shift
      ;;
    --openai-model)
      OPENAI_MODEL="$2"
      shift 2
      ;;
    *)
      echo "Unknown option: $1"
      usage
      exit 1
      ;;
  esac
done

# ---- Helper functions --------------------------------------------------------

log() {
  echo -e "${BLUE}[agentsmd]${NC} $*"
}

log_verbose() {
  if [[ "$VERBOSE" == "true" ]]; then
    echo -e "${BLUE}[agentsmd]${NC} $*"
  fi
}

log_error() {
  echo -e "${RED}[agentsmd ERROR]${NC} $*" >&2
}

log_success() {
  echo -e "${GREEN}[agentsmd]${NC} $*"
}

log_warning() {
  echo -e "${YELLOW}[agentsmd]${NC} $*"
}

# Log with tier indicator
log_tier() {
  local tier="$1"
  shift
  local tier_tag=""
  case "$tier" in
    public)
      tier_tag="${GREEN}[public]${NC}"
      ;;
    team)
      tier_tag="${BLUE}[team]${NC}"
      ;;
    private)
      tier_tag="${YELLOW}[private]${NC}"
      ;;
  esac
  echo -e "${BLUE}[agentsmd]${NC} ${tier_tag} $*"
}

# Check if a command exists
command_exists() {
  command -v "$1" >/dev/null 2>&1
}

# Ensure required directories exist
ensure_directories() {
  mkdir -p "$BEST_PRACTICES_DIR"
  mkdir -p "$CACHE_DIR"
  mkdir -p "$TEMPLATES_DIR"
  mkdir -p "$LIB_DIR"
}

# List available rules
list_rules() {
  log "Available rules:"
  local found_any=false
  
  # Iterate through all repos
  for i in "${!AGENTSMD_REPOS[@]}"; do
    local repo_root="${AGENTSMD_REPOS[$i]}"
    local tier="${TIER_NAMES[$i]}"
    local rules_dir="${repo_root}/rules"
    
    if [[ -d "$rules_dir" ]]; then
      local tier_rules=()
      while IFS= read -r -d '' rule; do
        tier_rules+=("$rule")
      done < <(find "$rules_dir" -name "*.mdc" -type f -print0 | sort -z)
      
      if [[ ${#tier_rules[@]} -gt 0 ]]; then
        found_any=true
        if [[ "$VERBOSE" == "true" ]]; then
          log_tier "$tier" "Rules from $rules_dir:"
        fi
        
        for rule in "${tier_rules[@]}"; do
          local relative_path="${rule#$rules_dir/}"
          # Extract description from frontmatter
          local desc=$(awk '/^---$/{if(++n==2)exit} /^description:/{gsub(/^description:[[:space:]]*/, ""); print}' "$rule" 2>/dev/null || echo "")
          if [[ "$VERBOSE" == "true" ]]; then
            printf "  %-30s %s ${GREEN}[%s]${NC}\n" "$relative_path" "$desc" "$tier"
          else
            printf "  %-30s %s\n" "$relative_path" "$desc"
          fi
        done
      fi
    fi
  done
  
  if [[ "$found_any" == "false" ]]; then
    log_error "No rules found in any configured repository"
  fi
}

# List available migrations
list_migrations() {
  log "Available migrations:"
  local found_any=false
  
  # Iterate through all repos
  for i in "${!AGENTSMD_REPOS[@]}"; do
    local repo_root="${AGENTSMD_REPOS[$i]}"
    local tier="${TIER_NAMES[$i]}"
    local practices_dir="${repo_root}/best-practices"
    
    if [[ -d "$practices_dir" ]]; then
      local tier_migrations=()
      while IFS= read -r -d '' migration; do
        tier_migrations+=("$migration")
      done < <(find "$practices_dir" -name "*.md" -type f -print0 | sort -z)
      
      if [[ ${#tier_migrations[@]} -gt 0 ]]; then
        found_any=true
        if [[ "$VERBOSE" == "true" ]]; then
          log_tier "$tier" "Migrations from $practices_dir:"
        fi
        
        for migration in "${tier_migrations[@]}"; do
          local basename=$(basename "$migration")
          # Extract description from first comment line if present
          local desc=$(grep -m1 '^# Description:' "$migration" 2>/dev/null | sed 's/# Description: //' || echo "")
          if [[ "$VERBOSE" == "true" ]]; then
            printf "  %-30s %s ${GREEN}[%s]${NC}\n" "$basename" "$desc" "$tier"
          else
            printf "  %-30s %s\n" "$basename" "$desc"
          fi
        done
      fi
    fi
  done
  
  if [[ "$found_any" == "false" ]]; then
    log_error "No migrations found in any configured repository"
  fi
}

# Get project absolute path
get_project_path() {
  if [[ ! -d "$PROJECT_DIR" ]]; then
    log_error "Project directory does not exist: $PROJECT_DIR"
    exit 1
  fi
  echo "$(cd "$PROJECT_DIR" && pwd)"
}

# Generate cache key for a prompt
generate_cache_key() {
  local prompt="$1"
  local project_path="$2"
  
  # Get git commit hash if in git repo
  local git_hash="no-git"
  if [[ -d "$project_path/.git" ]]; then
    git_hash=$(cd "$project_path" && git rev-parse HEAD 2>/dev/null || echo "no-git")
  fi
  
  # Get key file timestamps
  local key_files=""
  if command_exists find && command_exists stat && command_exists md5sum; then
    key_files=$(cd "$project_path" && \
      find . -name "*.json" -o -name "*.yaml" -o -name "*.yml" -o -name "package.json" | \
      head -20 | \
      xargs stat -c "%Y" 2>/dev/null | \
      sort | \
      md5sum | \
      cut -d' ' -f1 || echo "no-files")
  fi
  
  # Combine into cache key
  local prompt_hash=$(echo -n "$prompt" | md5sum | cut -d' ' -f1)
  echo "${prompt_hash:0:8}-${git_hash:0:8}-${key_files:0:8}-${CLAUDE_MODEL}"
}

# Get cache file path
get_cache_path() {
  local cache_key="$1"
  local project_name=$(basename "$2")
  echo "$CACHE_DIR/${project_name}/${cache_key}.txt"
}

# Run Claude Code analysis
run_claude_analysis() {
  local prompt="$1"
  local cache_key="$2"
  local cache_file="$3"
  
  if [[ "$SHOW_PROMPTS" == "true" ]]; then
    log_verbose "Claude prompt:"
    echo "$prompt" | sed 's/^/  /'
  fi
  
  # Check cache first
  if [[ "$NO_CACHE" == "false" && -f "$cache_file" ]]; then
    log_verbose "Using cached result: $cache_file"
    cat "$cache_file"
    return 0
  fi
  
  # Ensure Claude Code is available
  if ! command_exists claude; then
    log_error "Claude Code CLI not found. Please install it first."
    echo "[Claude Code not available - analysis skipped]"
    return 1
  fi
  
  log_verbose "Running Claude analysis..."
  
  local output=""
  local exit_code=0
  local retry_count=0
  local error_file=$(mktemp)
  
  # Determine timeout command (macOS vs Linux)
  local timeout_cmd="timeout"
  if ! command -v timeout &> /dev/null; then
    if command -v gtimeout &> /dev/null; then
      timeout_cmd="gtimeout"
    else
      log_error "Neither 'timeout' nor 'gtimeout' found. Please install coreutils."
      return 1
    fi
  fi

  # Retry loop with exponential backoff
  while [[ $retry_count -lt $MAX_RETRIES ]]; do
    # Execute Claude Code with timeout
    if output=$($timeout_cmd "$TIMEOUT" claude --print --dangerously-skip-permissions --output-format text --model "$CLAUDE_MODEL" "$prompt" 2>"$error_file"); then
      exit_code=0
      break
    else
      exit_code=$?
      retry_count=$((retry_count + 1))
      
      if [[ $retry_count -lt $MAX_RETRIES ]]; then
        local wait_time=$((2 ** retry_count))
        log_warning "Claude analysis failed (attempt $retry_count/$MAX_RETRIES), retrying in ${wait_time}s..."
        if [[ -s "$error_file" ]]; then
          log_warning "Error: $(head -n 3 "$error_file" | tr '\n' ' ')"
        fi
        sleep "$wait_time"
      fi
    fi
  done
  
  if [[ $exit_code -eq 0 && -n "$output" ]]; then
    # Success - save to cache
    mkdir -p "$(dirname "$cache_file")"
    echo "$output" > "$cache_file"
    echo "$output"
    rm -f "$error_file"
    return 0
  else
    # Error - log and return error
    log_error "Claude Code failed after $MAX_RETRIES attempts (exit code: $exit_code)"
    if [[ -s "$error_file" ]]; then
      log_error "Error details:"
      cat "$error_file" >&2
    else
      if [[ $exit_code -eq 124 ]]; then
        log_error "Claude command timed out after ${TIMEOUT} seconds"
      else
        log_error "No error details captured. Claude may have been terminated."
      fi
    fi
    rm -f "$error_file"
    return 1
  fi
}

# Process a migration file
process_migration() {
  local migration_file="$1"
  local project_path="$2"
  local migration_name=$(basename "$migration_file")
  
  log_verbose "Processing migration: $migration_name"
  
  local content=$(cat "$migration_file")
  local processed_content=""
  local remaining_content="$content"
  
  # Process all Claude prompts in the migration using a more robust approach
  while true; do
    # Find the start of the next Claude prompt
    local start_marker="{{CLAUDE_PROMPT}}"
    local end_marker="{{/CLAUDE_PROMPT}}"
    
    # Check if there's a Claude prompt in the remaining content
    if [[ "$remaining_content" != *"$start_marker"* ]]; then
      break
    fi
    
    # Extract content before the start marker
    local before_match="${remaining_content%%$start_marker*}"
    processed_content+="$before_match"
    
    # Remove the processed part and the start marker
    remaining_content="${remaining_content#*$start_marker}"
    
    # Find the end marker
    if [[ "$remaining_content" != *"$end_marker"* ]]; then
      log_error "Found $start_marker without matching $end_marker in migration: $migration_name"
      return 1
    fi
    
    # Extract the prompt content
    local prompt="${remaining_content%%$end_marker*}"
    
    # Trim whitespace from prompt
    prompt=$(echo "$prompt" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
    
    # Generate cache key and run analysis
    local cache_key=$(generate_cache_key "$prompt" "$project_path")
    local cache_file=$(get_cache_path "$cache_key" "$project_path")
    
    # Change to project directory for Claude analysis
    local result
    if ! result=$(cd "$project_path" && run_claude_analysis "$prompt" "$cache_key" "$cache_file"); then
      log_error "Claude analysis failed for migration: $migration_name"
      log_error "Stopping migration process to prevent incomplete AGENTS.md"
      return 1
    fi
    
    # Add the result (without the prompt markers or the prompt itself)
    processed_content+="$result"
    
    # Update remaining content to start after the end marker
    remaining_content="${remaining_content#*$end_marker}"
  done
  
  # Add any remaining content
  processed_content+="$remaining_content"
  
  echo "$processed_content"
  return 0
}

# Read version file
read_version_file() {
  local version_file="$1"
  local tier="${2:-public}"  # Default to public tier
  
  if [[ ! -f "$version_file" ]]; then
    echo "0"
    return
  fi
  
  # Use yq if available, otherwise parse manually
  if command_exists yq; then
    case "$tier" in
      public)
        yq eval '.agentsmd.version // 0' "$version_file" 2>/dev/null || echo "0"
        ;;
      team)
        yq eval '.agentsmd.team_version // 0' "$version_file" 2>/dev/null || echo "0"
        ;;
      private)
        yq eval '.agentsmd.private_version // 0' "$version_file" 2>/dev/null || echo "0"
        ;;
    esac
  else
    # Fallback to grep for specific version field
    case "$tier" in
      public)
        grep -m1 '^[[:space:]]*version:' "$version_file" 2>/dev/null | sed 's/.*version:[[:space:]]*//' || echo "0"
        ;;
      team)
        grep -m1 '^[[:space:]]*team_version:' "$version_file" 2>/dev/null | sed 's/.*team_version:[[:space:]]*//' || echo "0"
        ;;
      private)
        grep -m1 '^[[:space:]]*private_version:' "$version_file" 2>/dev/null | sed 's/.*private_version:[[:space:]]*//' || echo "0"
        ;;
    esac
  fi
}

# Write version file
write_version_file() {
  local version_file="$1"
  local public_version="$2"
  local team_version="$3"
  local private_version="$4"
  local cache_key="$5"
  
  cat > "$version_file" <<EOF
# Agentyard version tracking
agentsmd:
  version: $public_version
  team_version: $team_version
  private_version: $private_version
  applied_at: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
  cache_key: "$cache_key"
EOF
}

# Calculate checksum of a file
calculate_checksum() {
  local file="$1"
  if command_exists sha256sum; then
    sha256sum "$file" | cut -d' ' -f1
  elif command_exists shasum; then
    shasum -a 256 "$file" | cut -d' ' -f1
  else
    # Fallback to md5 if sha256 not available
    md5sum "$file" 2>/dev/null | cut -d' ' -f1 || md5 "$file" 2>/dev/null | awk '{print $NF}'
  fi
}

# Read rules tracking file
read_rules_file() {
  local rules_file="$1"
  
  if [[ ! -f "$rules_file" ]]; then
    echo ""
    return
  fi
  
  cat "$rules_file"
}

# Write rules tracking file
write_rules_file() {
  local rules_file="$1"
  local content="$2"
  
  echo "$content" > "$rules_file"
}

# Get rule entry from tracking file
get_rule_entry() {
  local rules_content="$1"
  local rule_path="$2"
  
  echo "$rules_content" | grep -A2 "^- path: $rule_path" || echo ""
}

# Sync rules to project directory
sync_rules() {
  local project_path="$1"
  local rules_file="$project_path/.agentyard-rules.yml"
  local target_dir="$project_path/docs/agentyard/rules"
  local synced_rules=()
  local skipped_rules=()
  local new_rules=()
  local overridden_rules=()
  
  log_verbose "Syncing rules to project..."
  
  # Read existing rules tracking
  local rules_content=$(read_rules_file "$rules_file")
  
  # Create target directory if needed
  if [[ ! -d "$target_dir" ]]; then
    if [[ "$CHECK_ONLY" == "true" ]]; then
      log "Would create directory: $target_dir"
    else
      mkdir -p "$target_dir"
      log_verbose "Created rules directory: $target_dir"
    fi
  fi
  
  # Start building new rules content
  local new_rules_content="# Agentyard rules tracking
rules:"
  
  # Collect all rules from all tiers with precedence
  declare -A rule_sources  # Maps relative path to source file and tier
  declare -A rule_tiers    # Maps relative path to tier name
  
  # Process repos in order (public, team, private)
  for i in "${!AGENTSMD_REPOS[@]}"; do
    local repo_root="${AGENTSMD_REPOS[$i]}"
    local tier="${TIER_NAMES[$i]}"
    local rules_dir="${repo_root}/rules"
    
    if [[ -d "$rules_dir" ]]; then
      while IFS= read -r -d '' rule_file; do
        local relative_path="${rule_file#$rules_dir/}"
        
        # Check if rule already exists from a lower-priority tier
        if [[ -n "${rule_sources[$relative_path]:-}" ]]; then
          # Rule exists - higher tier overrides
          local prev_tier="${rule_tiers[$relative_path]}"
          if [[ "$DRY_RUN" == "true" || "$VERBOSE" == "true" ]]; then
            log_tier "$tier" "Override: $relative_path (was from $prev_tier)"
          fi
          overridden_rules+=("$relative_path: $prev_tier -> $tier")
        fi
        
        # Store rule source (later tiers override earlier ones)
        rule_sources["$relative_path"]="$rule_file"
        rule_tiers["$relative_path"]="$tier"
      done < <(find "$rules_dir" -name "*.mdc" -type f -print0 | sort -z)
    fi
  done
  
  # Now sync the collected rules
  for relative_path in "${!rule_sources[@]}"; do
    local rule_file="${rule_sources[$relative_path]}"
    local tier="${rule_tiers[$relative_path]}"
    local target_file="$target_dir/$relative_path"
    local target_file_dir=$(dirname "$target_file")
    local source_checksum=$(calculate_checksum "$rule_file")
    
    # Create subdirectory if needed
    if [[ ! -d "$target_file_dir" ]] && [[ "$target_file_dir" != "$target_dir" ]]; then
      if [[ "$CHECK_ONLY" == "false" ]]; then
        mkdir -p "$target_file_dir"
      fi
    fi
    
    # Check if file exists and needs sync
    local should_sync=true
    local sync_reason=""
    
    if [[ -f "$target_file" ]]; then
      local existing_entry=$(get_rule_entry "$rules_content" "$relative_path")
      if [[ -n "$existing_entry" ]]; then
        local tracked_checksum=$(echo "$existing_entry" | grep "checksum:" | sed 's/.*checksum: //' | tr -d '"')
        local current_checksum=$(calculate_checksum "$target_file")
        
        if [[ "$tracked_checksum" != "$current_checksum" ]]; then
          # Local modifications detected
          should_sync=false
          sync_reason="local modifications"
          skipped_rules+=("$relative_path")
        elif [[ "$tracked_checksum" != "$source_checksum" ]]; then
          # Update available
          sync_reason="update available"
        else
          # Already up to date
          should_sync=false
          sync_reason="already up to date"
        fi
      else
        # File exists but not tracked - treat as local modification
        should_sync=false
        sync_reason="untracked local file"
        skipped_rules+=("$relative_path")
      fi
    else
      sync_reason="new rule"
      new_rules+=("$relative_path")
    fi
    
    # Perform sync if needed
    if [[ "$should_sync" == "true" ]]; then
      if [[ "$CHECK_ONLY" == "true" || "$DRY_RUN" == "true" ]]; then
        log "Would sync: $relative_path ($sync_reason) [${tier}]"
      else
        cp "$rule_file" "$target_file"
        synced_rules+=("$relative_path")
        if [[ "$VERBOSE" == "true" ]]; then
          log_tier "$tier" "Synced: $relative_path ($sync_reason)"
        else
          log_verbose "Synced: $relative_path ($sync_reason)"
        fi
      fi
    else
      if [[ "$VERBOSE" == "true" ]]; then
        log_tier "$tier" "Skipped: $relative_path ($sync_reason)"
      else
        log_verbose "Skipped: $relative_path ($sync_reason)"
      fi
    fi
    
    # Add to tracking content
    new_rules_content+="
- path: $relative_path
  checksum: $source_checksum
  source_tier: $tier
  synced_at: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
  done
  
  # Write updated rules tracking file
  if [[ "$CHECK_ONLY" == "false" && "$DRY_RUN" == "false" ]] && [[ ${#synced_rules[@]} -gt 0 || ${#new_rules[@]} -gt 0 ]]; then
    write_rules_file "$rules_file" "$new_rules_content"
    log_verbose "Updated rules tracking file"
  fi
  
  # Report results
  if [[ ${#overridden_rules[@]} -gt 0 && ( "$DRY_RUN" == "true" || "$VERBOSE" == "true" ) ]]; then
    log "Rule overrides detected:"
    for override in "${overridden_rules[@]}"; do
      log "  - $override"
    done
  fi
  
  if [[ ${#new_rules[@]} -gt 0 ]]; then
    log "Found ${#new_rules[@]} new rule(s)"
  fi
  
  if [[ ${#synced_rules[@]} -gt 0 ]]; then
    log "Synced ${#synced_rules[@]} rule(s)"
  fi
  
  if [[ ${#skipped_rules[@]} -gt 0 ]]; then
    log_warning "Skipped ${#skipped_rules[@]} rule(s) with local modifications:"
    for rule in "${skipped_rules[@]}"; do
      log_warning "  - $rule"
    done
  fi
  
  # Return list of all rules for AGENTS.md generation
  echo "$new_rules_content" | grep "^- path:" | sed 's/- path: //'
}

# Get list of rules in project
get_project_rules() {
  local project_path="$1"
  local rules_dir="$project_path/docs/agentyard/rules"
  
  if [[ -d "$rules_dir" ]]; then
    find "$rules_dir" -name "*.mdc" -type f | sort | while read -r rule_file; do
      echo "${rule_file#$project_path/}"
    done
  fi
}

# Create symlink if it doesn't exist
create_symlink() {
  local source="$1"
  local target="$2"
  
  if [[ -L "$target" ]]; then
    log_verbose "Symlink already exists: $target -> $(readlink "$target")"
  elif [[ -e "$target" ]]; then
    log_warning "File exists but is not a symlink: $target"
  else
    if [[ "$CHECK_ONLY" == "true" ]]; then
      log "Would create symlink: $target -> $source"
    else
      ln -s "$source" "$target"
      log_success "Created symlink: $target -> $source"
    fi
  fi
}

# Wrap lines in markdown content while preserving formatting
wrap_markdown_content() {
  local content="$1"
  local max_width=120
  
  # Check if fmt is available
  if ! command_exists fmt; then
    log_warning "fmt command not found. Skipping line wrapping."
    echo "$content"
    return 0
  fi
  
  # Create temporary files for processing
  local temp_input=$(mktemp)
  local temp_output=$(mktemp)
  local temp_code=$(mktemp)
  
  # Write content to temp file
  echo "$content" > "$temp_input"
  
  # Track if we're in a code block
  local in_code_block=false
  local code_block_delimiter=""
  local line_num=0
  
  # Process line by line
  while IFS= read -r line; do
    line_num=$((line_num + 1))
    
    # Check for code block markers
    if [[ "$line" =~ ^(\`{3,}|\~{3,}) ]]; then
      if [[ "$in_code_block" == "false" ]]; then
        in_code_block=true
        code_block_delimiter="${BASH_REMATCH[1]}"
        echo "$line" >> "$temp_output"
        continue
      elif [[ "$line" =~ ^${code_block_delimiter} ]]; then
        in_code_block=false
        code_block_delimiter=""
        echo "$line" >> "$temp_output"
        continue
      fi
    fi
    
    # If in code block, preserve as-is
    if [[ "$in_code_block" == "true" ]]; then
      echo "$line" >> "$temp_output"
      continue
    fi
    
    # Handle special markdown elements
    # Headers (preserve as-is)
    if [[ "$line" =~ ^#+ ]]; then
      echo "$line" >> "$temp_output"
      continue
    fi
    
    # Empty lines (preserve)
    if [[ -z "$line" || "$line" =~ ^[[:space:]]*$ ]]; then
      echo "$line" >> "$temp_output"
      continue
    fi
    
    # Lists - handle specially to preserve indentation
    if [[ "$line" =~ ^([[:space:]]*)([*+-]|[0-9]+\.)([[:space:]]+)(.*)$ ]]; then
      local indent="${BASH_REMATCH[1]}"
      local marker="${BASH_REMATCH[2]}"
      local space="${BASH_REMATCH[3]}"
      local content="${BASH_REMATCH[4]}"
      
      # Check if content is empty or just whitespace
      if [[ -z "$content" || "$content" =~ ^[[:space:]]*$ ]]; then
        echo "$line" >> "$temp_output"
        continue
      fi
      
      # Check if content contains a URL
      if [[ "$content" =~ https?://[^[:space:]]+ ]]; then
        echo "$line" >> "$temp_output"
      else
        # Calculate available width for content
        local prefix_len=$((${#indent} + ${#marker} + ${#space}))
        local content_width=$((max_width - prefix_len))
        
        # Ensure we have a positive width
        if [[ $content_width -lt 20 ]]; then
          # Line is already too indented, just preserve it
          echo "$line" >> "$temp_output"
        else
          # Wrap the content part only
          local wrapped_content=$(echo "$content" | fmt -w $content_width)
          local first_line=true
          while IFS= read -r wrapped_line; do
            if [[ "$first_line" == "true" ]]; then
              echo "${indent}${marker}${space}${wrapped_line}" >> "$temp_output"
              first_line=false
            else
              # Continuation lines get extra indentation
              echo "${indent}    ${wrapped_line}" >> "$temp_output"
            fi
          done <<< "$wrapped_content"
        fi
      fi
      continue
    fi
    
    # Block quotes
    if [[ "$line" =~ ^(\>+[[:space:]]*)(.*)$ ]]; then
      local quote_marker="${BASH_REMATCH[1]}"
      local content="${BASH_REMATCH[2]}"
      
      # Check if content is empty
      if [[ -z "$content" || "$content" =~ ^[[:space:]]*$ ]]; then
        echo "$line" >> "$temp_output"
        continue
      fi
      
      # Check if content contains a URL
      if [[ "$content" =~ https?://[^[:space:]]+ ]]; then
        echo "$line" >> "$temp_output"
      else
        # Calculate available width
        local quote_width=$((max_width - ${#quote_marker}))
        if [[ $quote_width -lt 20 ]]; then
          # Too narrow, preserve as-is
          echo "$line" >> "$temp_output"
        else
          # Wrap the content part only
          local wrapped_content=$(echo "$content" | fmt -w $quote_width)
          while IFS= read -r wrapped_line; do
            echo "${quote_marker}${wrapped_line}" >> "$temp_output"
          done <<< "$wrapped_content"
        fi
      fi
      continue
    fi
    
    # Regular paragraphs - check for URLs
    if [[ "$line" =~ https?://[^[:space:]]+ ]]; then
      # Line contains URL, preserve as-is
      echo "$line" >> "$temp_output"
    else
      # Wrap normal text
      echo "$line" | fmt -w $max_width >> "$temp_output"
    fi
    
  done < "$temp_input"
  
  # Read the wrapped content
  local wrapped_content=$(cat "$temp_output")
  
  # Clean up temp files
  rm -f "$temp_input" "$temp_output" "$temp_code"
  
  echo "$wrapped_content"
}

# Run dedupe command
run_dedupe() {
  local project_path
  if ! project_path=$(get_project_path); then
    exit 1
  fi
  
  log "Running duplicate removal on AGENTS.md..."
  
  # Build command args
  local dedupe_args=()
  [[ "$DRY_RUN" == "true" ]] && dedupe_args+=("--dry-run")
  [[ "$VERBOSE" == "true" ]] && dedupe_args+=("--verbose")
  dedupe_args+=("--timeout" "$TIMEOUT")
  dedupe_args+=("--model" "$OPENAI_MODEL")
  dedupe_args+=("--max-retries" "$MAX_RETRIES")
  
  # Change to project directory and run dedupe
  if cd "$project_path" && "$SCRIPT_DIR/agentsmd-dedupe" "${dedupe_args[@]}"; then
    log_success "Duplicate removal complete!"
    return 0
  else
    log_error "Duplicate removal failed"
    return 1
  fi
}

# Main function
main() {
  # Handle commands
  if [[ "$COMMAND" == "dedupe" ]]; then
    run_dedupe
    exit $?
  fi
  
  # Handle list migrations
  if [[ "$LIST_MIGRATIONS" == "true" ]]; then
    list_migrations
    exit 0
  fi
  
  # Handle list rules
  if [[ "$LIST_RULES" == "true" ]]; then
    list_rules
    exit 0
  fi
  
  # Ensure directories exist
  ensure_directories
  
  # Get project path
  local project_path
  if ! project_path=$(get_project_path); then
    exit 1
  fi
  log "Working in: $project_path"
  
  # Paths for agent files
  local agents_file="$project_path/AGENTS.md"
  local claude_file="$project_path/CLAUDE.md"
  local gemini_file="$project_path/GEMINI.md"
  local version_file="$project_path/.agentyard-version.yml"
  
  # Create symlinks
  create_symlink "AGENTS.md" "$claude_file"
  create_symlink "AGENTS.md" "$gemini_file"
  
  # Read current versions for all tiers
  local public_version=$(read_version_file "$version_file" "public")
  local team_version=$(read_version_file "$version_file" "team")
  local private_version=$(read_version_file "$version_file" "private")
  
  if [[ "$VERBOSE" == "true" ]]; then
    log_verbose "Current versions - public: $public_version, team: $team_version, private: $private_version"
  fi
  
  # Collect all migrations from all tiers
  local all_migrations=()
  local migration_tiers=()
  local tier_versions=()
  tier_versions[0]=$public_version
  tier_versions[1]=$team_version
  tier_versions[2]=$private_version
  
  # Process each repository
  for i in "${!AGENTSMD_REPOS[@]}"; do
    local repo_root="${AGENTSMD_REPOS[$i]}"
    local tier="${TIER_NAMES[$i]}"
    local practices_dir="${repo_root}/best-practices"
    local current_tier_version="${tier_versions[$i]}"
    
    if [[ -d "$practices_dir" ]]; then
      while IFS= read -r -d '' file; do
        local migration_number=$(basename "$file" | grep -o '^[0-9]\+' || echo "0")
        if [[ $migration_number -gt $current_tier_version ]]; then
          all_migrations+=("$file")
          migration_tiers+=("$tier")
        fi
      done < <(find "$practices_dir" -name "*.md" -type f -print0 | sort -z)
    fi
  done
  
  if [[ ${#all_migrations[@]} -eq 0 ]]; then
    log "No new migrations to apply"
    # Still sync rules even if no new migrations
    sync_rules "$project_path" > /dev/null
    exit 0
  fi
  
  log "Found ${#all_migrations[@]} new migration(s) to apply"
  
  # Check only mode
  if [[ "$CHECK_ONLY" == "true" || "$DRY_RUN" == "true" ]]; then
    log "Migrations that would be applied:"
    for idx in "${!all_migrations[@]}"; do
      local migration="${all_migrations[$idx]}"
      local tier="${migration_tiers[$idx]}"
      if [[ "$VERBOSE" == "true" ]]; then
        echo "  - $(basename "$migration") [${tier}]"
      else
        echo "  - $(basename "$migration")"
      fi
    done
    # Also check rules
    sync_rules "$project_path" > /dev/null
    if [[ "$DRY_RUN" == "true" ]]; then
      exit 0
    fi
  fi
  
  # Apply migrations
  local agents_content=""
  if [[ -f "$agents_file" ]]; then
    agents_content=$(cat "$agents_file")
  fi
  
  # Track highest version for each tier
  local max_public_version=$public_version
  local max_team_version=$team_version
  local max_private_version=$private_version
  
  for idx in "${!all_migrations[@]}"; do
    local migration="${all_migrations[$idx]}"
    local tier="${migration_tiers[$idx]}"
    
    if [[ "$VERBOSE" == "true" ]]; then
      log_tier "$tier" "Applying migration: $(basename "$migration")"
    else
      log "Applying migration: $(basename "$migration")"
    fi
    
    # Process the migration
    local processed
    if ! processed=$(process_migration "$migration" "$project_path"); then
      log_error "Failed to process migration: $(basename "$migration")"
      log_error "Aborting agentsmd to prevent incomplete AGENTS.md file"
      exit 1
    fi
    
    # Append to content
    if [[ -n "$agents_content" ]]; then
      agents_content+="\n\n"
    fi
    agents_content+="$processed"
    
    # Update max version for the appropriate tier
    local migration_number=$(basename "$migration" | grep -o '^[0-9]\+' || echo "0")
    case "$tier" in
      public)
        if [[ $migration_number -gt $max_public_version ]]; then
          max_public_version=$migration_number
        fi
        ;;
      team)
        if [[ $migration_number -gt $max_team_version ]]; then
          max_team_version=$migration_number
        fi
        ;;
      private)
        if [[ $migration_number -gt $max_private_version ]]; then
          max_private_version=$migration_number
        fi
        ;;
    esac
  done
  
  # Sync rules
  sync_rules "$project_path" > /dev/null
  
  # Add rule references section
  local rule_files=$(get_project_rules "$project_path")
  if [[ -n "$rule_files" ]]; then
    agents_content+="\n\n## Additional Rules and References\n"
    while IFS= read -r rule_file; do
      agents_content+="\n@$rule_file"
    done <<< "$rule_files"
  fi
  
  # Wrap lines before writing
  log_verbose "Wrapping lines to 120 characters..."
  local wrapped_content
  if wrapped_content=$(wrap_markdown_content "$agents_content"); then
    agents_content="$wrapped_content"
    log_verbose "Line wrapping completed successfully"
  else
    log_warning "Line wrapping failed, using unwrapped content"
  fi
  
  # Write AGENTS.md
  echo -e "$agents_content" > "$agents_file"
  log_success "Updated $agents_file"
  
  # Update version file with all tier versions
  local cache_key=$(generate_cache_key "version" "$project_path")
  write_version_file "$version_file" "$max_public_version" "$max_team_version" "$max_private_version" "$cache_key"
  
  if [[ "$VERBOSE" == "true" ]]; then
    log_success "Updated versions - public: $max_public_version, team: $max_team_version, private: $max_private_version"
  else
    log_success "Updated version tracking"
  fi
  
  log_success "Done! AGENTS.md is now up to date."
}

# ---- Main execution ----------------------------------------------------------

main