#!/usr/bin/env bash
#
# judge  ‚Äì  AI-powered pull request reviewer using local LLM
#
# Usage:  judge <pr> [options]
#   pr        PR number or branch name
#
# Options:
#   --model MODEL      Use specific model (default: from config)
#   --config FILE      Use custom config file (default: ~/.agentyard/judge.yaml)
#   --init-config      Create default config file and exit
#   -h, --help         Show this help message
#
# Examples:
#   judge 45                           # Review PR #45
#   judge feature/new-login            # Review PR by branch name
#   judge 45 --model mistral-small     # Use specific model
#   judge --init-config                # Create default configuration
#
# Dependencies: gh, python3, llama-cpp-python
# Configuration: ~/.agentyard/judge.yaml
#
# Model Path Resolution (in order of precedence):
#   1. Per-model path in config file
#   2. $AGENTYARD_MODELS_PATH environment variable
#   3. models_dir in config file
#   4. ~/.agentyard/models/
#
set -euo pipefail

prog=$(basename "$0")
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Default configuration
DEFAULT_CONFIG="$HOME/.agentyard/judge.yaml"
DEFAULT_MODEL="mistral-small-2409"
MAX_DIFF_LINES=1000

# Colors for output
RED='\033[0;31m'
YELLOW='\033[0;33m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

usage() {
  cat <<EOF
Usage: $prog <pr> [options]
       $prog --init-config

  pr        PR number or branch name

Options:
  --model MODEL      Use specific model (default: from config)
  --config FILE      Use custom config file (default: ~/.agentyard/judge.yaml)
  --init-config      Create default config file and exit
  -h, --help         Show this help message

Examples:
  $prog 45                           # Review PR #45
  $prog feature/new-login            # Review PR by branch name
  $prog 45 --model mistral-small     # Use specific model
  $prog --init-config                # Create default configuration

Configuration:
  Default config file: ~/.agentyard/judge.yaml
  Model path resolution (in order):
    1. Per-model path in config
    2. \$AGENTYARD_MODELS_PATH/<model>.gguf
    3. Config models_dir setting
    4. ~/.agentyard/models/<model>.gguf
EOF
}

# ---- Parse arguments --------------------------------------------------------
if [[ $# -eq 0 || ${1:-} == "-h" || ${1:-} == "--help" ]]; then
  usage
  exit 0
fi

# Handle --init-config separately
if [[ ${1:-} == "--init-config" ]]; then
  init_config=true
  shift
  config_file="${1:-$DEFAULT_CONFIG}"
else
  init_config=false
  pr_input=$1
  shift
fi

config_file="${config_file:-$DEFAULT_CONFIG}"
model=""

while [[ $# -gt 0 ]]; do
  case $1 in
    --model)
      model="$2"
      shift 2
      ;;
    --config)
      config_file="$2"
      shift 2
      ;;
    *)
      echo "Error: Unknown option: $1" >&2
      usage
      exit 1
      ;;
  esac
done

# ---- Check dependencies -----------------------------------------------------
echo "üîç Checking dependencies..."

for cmd in gh python3; do
  if ! command -v "$cmd" >/dev/null; then
    echo -e "${RED}Error: $cmd not installed.${NC}" >&2
    echo "Please install required dependencies:" >&2
    echo "  - gh: https://cli.github.com/" >&2
    echo "  - python3: https://www.python.org/" >&2
    exit 1
  fi
done

# Check for Python dependencies
if ! python3 -c "import llama_cpp" 2>/dev/null; then
  echo -e "${YELLOW}Warning: llama-cpp-python not installed.${NC}" >&2
  echo "Installing llama-cpp-python..." >&2
  
  # Detect platform for Metal support
  if [[ "$(uname)" == "Darwin" ]]; then
    echo "Detected macOS - installing with Metal support..."
    CMAKE_ARGS="-DLLAMA_METAL=on" pip3 install llama-cpp-python --upgrade || {
      echo -e "${RED}Error: Failed to install llama-cpp-python${NC}" >&2
      exit 1
    }
  else
    pip3 install llama-cpp-python --upgrade || {
      echo -e "${RED}Error: Failed to install llama-cpp-python${NC}" >&2
      exit 1
    }
  fi
fi

# Check if PyYAML is installed for config parsing
if ! python3 -c "import yaml" 2>/dev/null; then
  echo "Installing PyYAML for configuration support..."
  pip3 install PyYAML || {
    echo -e "${RED}Error: Failed to install PyYAML${NC}" >&2
    exit 1
  }
fi

# Check if requests is installed for HuggingFace API
if ! python3 -c "import requests" 2>/dev/null; then
  echo "Installing requests for model management..."
  pip3 install requests || {
    echo -e "${RED}Error: Failed to install requests${NC}" >&2
    exit 1
  }
fi

# Check if psutil is installed for system specs
if ! python3 -c "import psutil" 2>/dev/null; then
  echo "Installing psutil for system detection..."
  pip3 install psutil || {
    echo -e "${RED}Error: Failed to install psutil${NC}" >&2
    exit 1
  }
fi

# ---- Handle --init-config ---------------------------------------------------
if [[ "$init_config" == "true" ]]; then
  echo "üìù Creating configuration file..."
  
  # Add Python path for our modules
  export PYTHONPATH="${SCRIPT_DIR}/../lib:${PYTHONPATH:-}"
  
  python3 - "$config_file" <<'EOF'
import sys
import os
import yaml
from pathlib import Path
from judge.model_manager import create_default_config

config_path = Path(sys.argv[1])

# Check if config already exists
if config_path.exists():
    response = input(f"Config file already exists at {config_path}. Overwrite? [y/N]: ").strip().lower()
    if response != 'y':
        print("Configuration creation cancelled.")
        sys.exit(0)

# Create directory if needed
config_path.parent.mkdir(parents=True, exist_ok=True)

# Create default config
config = create_default_config(config_path)

# Write config file
with open(config_path, 'w') as f:
    yaml.dump(config, f, default_flow_style=False, sort_keys=False)

print(f"‚úÖ Configuration created at: {config_path}")
print("\nDefault model: mistral-small-2409")
print(f"Models directory: {config['models_dir']}")
print("\nYou can now:")
print("  1. Set AGENTYARD_MODELS_PATH environment variable")
print("  2. Edit the config to set custom model paths")
print("  3. Run 'judge <pr>' to review a pull request")
EOF
  exit $?
fi

# ---- Check GitHub authentication --------------------------------------------
if ! gh auth status >/dev/null 2>&1; then
  echo -e "${RED}Error: Not authenticated with GitHub CLI${NC}" >&2
  echo "Please run: gh auth login" >&2
  exit 1
fi

# ---- Determine PR number from input -----------------------------------------
echo "üìã Resolving pull request..."

# Check if input is a number
if [[ "$pr_input" =~ ^[0-9]+$ ]]; then
  pr_number="$pr_input"
else
  # Try to find PR by branch name
  pr_number=$(gh pr list --state open --head "$pr_input" --json number --jq '.[0].number // empty' 2>/dev/null || true)
  
  if [[ -z "$pr_number" ]]; then
    echo -e "${RED}Error: No open PR found for branch '$pr_input'${NC}" >&2
    echo "Try using a PR number instead." >&2
    exit 1
  fi
  
  echo "Found PR #$pr_number for branch '$pr_input'"
fi

# ---- Create default config if it doesn't exist ------------------------------
if [[ ! -f "$config_file" ]]; then
  echo "Creating default configuration at $config_file..."
  echo "Run 'judge --init-config' to create a configuration file."
  exit 1
fi

# ---- Validate model early ---------------------------------------------------
echo "üîç Validating model..."

# Add Python path for our modules
export PYTHONPATH="${SCRIPT_DIR}/../lib:${PYTHONPATH:-}"

# Determine which model to use
if [[ -n "$model" ]]; then
  model_name="$model"
else
  # Extract model name from config
  model_name=$(python3 -c "
import yaml
with open('$config_file', 'r') as f:
    config = yaml.safe_load(f)
    print(config.get('model', {}).get('name', 'mistral-small-2409'))
" 2>/dev/null || echo "mistral-small-2409")
fi

# Validate and download model if needed
python3 - "$config_file" "$model_name" <<'EOF' || exit 1
import sys
from judge.model_manager import ModelManager

config_path = sys.argv[1]
model_name = sys.argv[2]

manager = ModelManager(config_path)
success, model_path = manager.validate_and_download_model(model_name)

if not success:
    print(f"‚ùå Failed to validate/download model: {model_name}")
    sys.exit(1)

print(f"‚úÖ Model validated: {model_path}")
EOF

# ---- Create Python helper script --------------------------------------------
helper_script="$SCRIPT_DIR/judge-ai.py"
echo "Creating AI helper script..."
cat > "$helper_script" <<'EOF'
#!/usr/bin/env python3
"""
judge-ai.py - AI helper for the judge command
Handles LLM loading and inference for PR reviews
"""

import sys
import json
import yaml
import os
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
import argparse

# Add parent directory to path for our modules
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'lib'))

try:
    from llama_cpp import Llama
except ImportError:
    print("Error: llama-cpp-python not installed", file=sys.stderr)
    sys.exit(1)

try:
    from judge.model_manager import ModelManager
except ImportError:
    print("Error: Could not import model manager", file=sys.stderr)
    sys.exit(1)


def load_config(config_path: str) -> Dict[str, Any]:
    """Load configuration from YAML file"""
    try:
        config_path = os.path.expanduser(config_path)
        with open(config_path, 'r') as f:
            return yaml.safe_load(f) or {}
    except Exception as e:
        print(f"Error loading config: {e}", file=sys.stderr)
        # Return default config
        return {
            "model": {
                "name": "mistral-small-2409",
                "context_size": 32768,
                "gpu_layers": -1,
                "temperature": 0.1,
                "max_tokens": 4096
            },
            "review": {
                "max_diff_lines": 1000,
                "include_pr_description": True,
                "output_format": "markdown"
            }
        }


def create_review_prompt(pr_data: Dict[str, Any], diff_content: str) -> Tuple[str, str]:
    """Create the prompt for code review"""
    system_prompt = """You are an expert code reviewer called "Judge". Your role is to:
1. Identify bugs, security issues, and logic errors
2. Suggest improvements for code quality and maintainability
3. Acknowledge good practices and well-written code
4. Focus on actionable, specific feedback
5. Be constructive and professional in tone

Review the following pull request and provide detailed feedback."""

    pr_title = pr_data.get('title', 'Untitled PR')
    pr_description = pr_data.get('body', 'No description provided')
    
    user_prompt = f"""PR Title: {pr_title}
Description: {pr_description}

Changed Files:
{', '.join(pr_data.get('files', []))}

Diff:
{diff_content}

Please provide a comprehensive code review with:
- Summary of critical issues, important concerns, and suggestions
- Detailed file-by-file analysis with line references
- Positive feedback on well-written code
- Actionable recommendations for improvements"""

    return system_prompt, user_prompt


def format_review_output(response: str) -> str:
    """Format the AI response into structured markdown"""
    # The model should already return well-formatted markdown,
    # but we can add additional formatting if needed
    
    if not response.strip().startswith("#"):
        # Add header if missing
        response = f"## AI Code Review\n\n{response}"
    
    return response


def run_review(config_path: str, pr_data_json: str, diff_content: str, 
               model_override: Optional[str] = None) -> None:
    """Run the AI review on the PR"""
    try:
        # Load configuration
        config = load_config(config_path)
        model_config = config.get('model', {})
        
        # Determine model name
        model_name = model_override or model_config.get('name', 'mistral-small-2409')
        
        # Use ModelManager to get model path
        manager = ModelManager(config_path)
        model_path = manager.get_model_path(model_name)
        
        # Verify model exists (should already be validated by main script)
        if not model_path.exists():
            print(f"Error: Model file not found at {model_path}", file=sys.stderr)
            print("The model should have been validated earlier. Please check your setup.", file=sys.stderr)
            sys.exit(1)
        
        # Parse PR data
        pr_data = json.loads(pr_data_json)
        
        # Create prompt
        system_prompt, user_prompt = create_review_prompt(pr_data, diff_content)
        
        # Initialize model with progress indicator
        print("ü§ñ Loading AI model...", file=sys.stderr)
        llm = Llama(
            model_path=str(model_path),
            n_ctx=model_config.get('context_size', 32768),
            n_gpu_layers=model_config.get('gpu_layers', -1),
            verbose=False
        )
        
        # Run inference
        print("üîç Analyzing code changes...", file=sys.stderr)
        response = llm.create_chat_completion(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=model_config.get('temperature', 0.1),
            max_tokens=model_config.get('max_tokens', 4096),
            stream=False
        )
        
        # Extract and format the response
        review_text = response['choices'][0]['message']['content']
        formatted_review = format_review_output(review_text)
        
        # Output the review
        print(formatted_review)
        
    except Exception as e:
        print(f"Error during AI review: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description='AI helper for judge PR reviewer')
    parser.add_argument('config_path', help='Path to configuration file')
    parser.add_argument('pr_data', help='PR data as JSON')
    parser.add_argument('diff_content', help='Diff content')
    parser.add_argument('--model', help='Model override', default=None)
    
    args = parser.parse_args()
    
    run_review(args.config_path, args.pr_data, args.diff_content, args.model)


if __name__ == '__main__':
    main()
EOF
chmod +x "$helper_script"

# ---- Fetch PR information ---------------------------------------------------
echo "üì• Fetching PR #$pr_number..."

# Get PR metadata
pr_data=$(gh pr view "$pr_number" --json title,body,files,headRefName || {
  echo -e "${RED}Error: Failed to fetch PR information${NC}" >&2
  exit 1
})

# Extract branch name for diff
branch_name=$(echo "$pr_data" | jq -r '.headRefName')
files_changed=$(echo "$pr_data" | jq -r '.files | length')

echo "Branch: $branch_name"
echo "Files changed: $files_changed"

# Get the diff
echo "üìä Fetching diff..."
diff_content=$(gh pr diff "$pr_number" || {
  echo -e "${RED}Error: Failed to fetch PR diff${NC}" >&2
  exit 1
})

# Check diff size
diff_lines=$(echo "$diff_content" | wc -l)
if [[ $diff_lines -gt $MAX_DIFF_LINES ]]; then
  echo -e "${YELLOW}Warning: Large diff ($diff_lines lines). Truncating to $MAX_DIFF_LINES lines.${NC}"
  diff_content=$(echo "$diff_content" | head -n "$MAX_DIFF_LINES")
fi

# ---- Run AI review ----------------------------------------------------------
echo "üöÄ Starting AI review..."

# Prepare files list
files_list=$(echo "$pr_data" | jq -r '.files[].path' | paste -sd, -)
pr_data_with_files=$(echo "$pr_data" | jq --arg files "$files_list" '. + {files: ($files | split(","))}')

# Run the Python helper
review_output=$(python3 "$helper_script" \
  "$config_file" \
  "$pr_data_with_files" \
  "$diff_content" \
  ${model:+--model "$model"} || {
    echo -e "${RED}Error: AI review failed${NC}" >&2
    exit 1
  })

# ---- Output the review ------------------------------------------------------
echo
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
echo
echo "$review_output"
echo
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
echo
echo -e "${GREEN}‚úÖ Review complete!${NC}"

# Optional: Save review to file
if [[ -n "${JUDGE_SAVE_REVIEWS:-}" ]]; then
  review_dir="$HOME/.agentyard/reviews"
  mkdir -p "$review_dir"
  review_file="$review_dir/pr-${pr_number}-$(date +%Y%m%d-%H%M%S).md"
  echo "$review_output" > "$review_file"
  echo "Review saved to: $review_file"
fi